{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Outputing CAM of tiles\n",
    "\n",
    "Created on 04/21/2020\n",
    "\n",
    "@author: RH\n",
    "\n",
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import data_input\n",
    "from slim import slim\n",
    "from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_file\n",
    "\n",
    "\n",
    "# format activation and weight to get heatmap\n",
    "def py_returnCAMmap(activation, weights_LR):\n",
    "    n_feat, w, h, n = activation.shape\n",
    "    act_vec = np.reshape(activation, [n_feat, w*h])\n",
    "    n_top = weights_LR.shape[0]\n",
    "    out = np.zeros([w, h, n_top])\n",
    "\n",
    "    for t in range(n_top):\n",
    "        weights_vec = np.reshape(weights_LR[t], [1, weights_LR[t].shape[0]])\n",
    "        heatmap_vec = np.dot(weights_vec,act_vec)\n",
    "        heatmap = np.reshape(np.squeeze(heatmap_vec), [w, h])\n",
    "        out[:, :, t] = heatmap\n",
    "    return out\n",
    "\n",
    "\n",
    "# image to double\n",
    "def im2double(im):\n",
    "    return cv2.normalize(im.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "\n",
    "\n",
    "# image to jpg\n",
    "def py_map2jpg(imgmap):\n",
    "    heatmap_x = np.round(imgmap*255).astype(np.uint8)\n",
    "    return cv2.applyColorMap(heatmap_x, cv2.COLORMAP_JET)\n",
    "\n",
    "\n",
    "# CAM for real test; no need to determine correct or wrong\n",
    "def CAM(net, w, pred, x, path, name, bs, rd=0):\n",
    "    DIRR = \"../Results/{}/out/{}_img\".format(path, name)\n",
    "    rd = rd * bs\n",
    "\n",
    "    try:\n",
    "        os.mkdir(DIRR)\n",
    "    except(FileExistsError):\n",
    "        pass\n",
    "\n",
    "    pdx = np.asmatrix(pred)\n",
    "\n",
    "    prl = pdx.argmax(axis=1).astype('uint8')\n",
    "\n",
    "    for ij in range(len(prl)):\n",
    "        id = str(ij + rd)\n",
    "        weights_LR = w\n",
    "        activation_lastconv = np.array([net[ij]])\n",
    "        weights_LR = weights_LR.T\n",
    "        activation_lastconv = activation_lastconv.T\n",
    "\n",
    "        topNum = 1  # generate heatmap for top X prediction results\n",
    "        curCAMmapAll = py_returnCAMmap(activation_lastconv, weights_LR[[1], :])\n",
    "        for kk in range(topNum):\n",
    "            curCAMmap_crops = curCAMmapAll[:, :, kk]\n",
    "            curCAMmapLarge_crops = cv2.resize(curCAMmap_crops, (299, 299))\n",
    "            curHeatMap = cv2.resize(im2double(curCAMmapLarge_crops), (299, 299))  # this line is not doing much\n",
    "            curHeatMap = im2double(curHeatMap)\n",
    "            curHeatMap = py_map2jpg(curHeatMap)\n",
    "            xim = x[ij].reshape(-1, 3)\n",
    "            xim1 = xim[:, 0].reshape(-1, 299)\n",
    "            xim2 = xim[:, 1].reshape(-1, 299)\n",
    "            xim3 = xim[:, 2].reshape(-1, 299)\n",
    "            image = np.empty([299, 299, 3])\n",
    "            image[:, :, 0] = xim1\n",
    "            image[:, :, 1] = xim2\n",
    "            image[:, :, 2] = xim3\n",
    "            a = im2double(image) * 255\n",
    "            b = im2double(curHeatMap) * 255\n",
    "            curHeatMap = a * 0.6 + b * 0.4\n",
    "            ab = np.hstack((a, b))\n",
    "            full = np.hstack((curHeatMap, ab))\n",
    "            # imname = DIRR + '/' + id + '.png'\n",
    "            # imname1 = DIRR + '/' + id + '_img.png'\n",
    "            # imname2 = DIRR + '/' + id +'_hm.png'\n",
    "            imname3 = DIRR + '/' + id + '_full.png'\n",
    "            # cv2.imwrite(imname, curHeatMap)\n",
    "            # cv2.imwrite(imname1, a)\n",
    "            # cv2.imwrite(imname2, b)\n",
    "            cv2.imwrite(imname3, full)\n",
    "\n",
    "\n",
    "def inference(images, num_classes, for_training=False, restore_logits=True,\n",
    "              scope=None):\n",
    "  \"\"\"Build Inception v3 model architecture.\n",
    "\n",
    "  See here for reference: http://arxiv.org/abs/1512.00567\n",
    "\n",
    "  Args:\n",
    "    images: Images returned from inputs() or distorted_inputs().\n",
    "    num_classes: number of classes\n",
    "    for_training: If set to `True`, build the inference model for training.\n",
    "      Kernels that operate differently for inference during training\n",
    "      e.g. dropout, are appropriately configured.\n",
    "    restore_logits: whether or not the logits layers should be restored.\n",
    "      Useful for fine-tuning a model with different num_classes.\n",
    "    scope: optional prefix string identifying the ImageNet tower.\n",
    "\n",
    "  Returns:\n",
    "    Logits. 2-D float Tensor.\n",
    "    Auxiliary Logits. 2-D float Tensor of side-head. Used for training only.\n",
    "  \"\"\"\n",
    "\n",
    "  # Set weight_decay for weights in Conv and FC layers.\n",
    "  with slim.arg_scope([slim.ops.conv2d, slim.ops.fc], weight_decay=0.00004):\n",
    "    with slim.arg_scope([slim.ops.conv2d],\n",
    "                        stddev=0.1,\n",
    "                        activation=tf.nn.relu,\n",
    "                        batch_norm_params={'decay': 0.9997, 'epsilon': 0.001}):\n",
    "      logits, endpoints, net2048, sel_endpoints, netts = slim.inception.inception_v3(\n",
    "          images,\n",
    "          dropout_keep_prob=0.8,\n",
    "          num_classes=num_classes,\n",
    "          is_training=for_training,\n",
    "          restore_logits=restore_logits,\n",
    "          scope=scope)\n",
    "\n",
    "  # Grab the logits associated with the side head. Employed during training.\n",
    "  auxiliary_logits = endpoints['aux_logits']\n",
    "\n",
    "  #return logits, auxiliary_logits\n",
    "  return logits, auxiliary_logits, endpoints, net2048, sel_endpoints, netts\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = '../Results/test.tfrecords'\n",
    "    datasets = data_input.DataSet(100, filename=filename)\n",
    "    itr, file, ph = datasets.data()\n",
    "    next_element = itr.get_next()\n",
    "    with tf.Session() as sesss:\n",
    "        sesss.run(itr.initializer, feed_dict={ph: file})\n",
    "        x = sesss.run(next_element)\n",
    "\n",
    "\n",
    "    # saver = tf.train.import_meta_graph('../model/model.ckpt-31500.meta')\n",
    "\n",
    "    # print(sess.run('logits/logits/weights:0'))\n",
    "    # print_tensors_in_checkpoint_file(file_name='../model/model.ckpt-31500', tensor_name='',\n",
    "    #                                  all_tensors=False, all_tensor_names=False)\n",
    "    with tf.Graph().as_default():\n",
    "        # image input\n",
    "        x_in = tf.placeholder(tf.float32, name=\"x\")\n",
    "        x_in_reshape = tf.reshape(x_in, [-1, 299, 299, 3])\n",
    "        logits, _, end_points, net2048, _, nett = inference(x_in_reshape, 2)\n",
    "        # # Restore the moving average version of the learned variables for eval.\n",
    "        # variable_averages = tf.train.ExponentialMovingAverage(\n",
    "        #     0.9997)\n",
    "        # variables_to_restore = variable_averages.variables_to_restore()\n",
    "        # saver = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "        with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "            tf.global_variables_initializer().run()\n",
    "            saver = tf.train.import_meta_graph('../model/model.ckpt-31500.meta')\n",
    "            # saver = tf.train.Saver(tf.all_variables(), reshape=True)\n",
    "            saver.restore(sess, '../model/model.ckpt-31500')\n",
    "            # x_in = tf.convert_to_tensor(x)\n",
    "            net2048_, end_points_, logits_, x_, nett_ = sess.run(\n",
    "                [logits, end_points, net2048, x_in_reshape, nett], {x_in: x})\n",
    "            weight = sess.run('logits/logits/weights:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
